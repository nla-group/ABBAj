---
title: 'ABBAj.jl: An accelerated ABBA in Julia'
tags:
- time series
- symbolic representation
- data mining




authors:
- name: Xinye Chen
  orcid: 0000-0003-1778-393X
  affiliation: 1
affiliations:
- name: Department of Mathematics, The University of Manchester
  index: 1
date: 11 March 2022
bibliography: paper.bib
---

# Summary

Adaptive Brownian bridge-based aggregation (ABBA) \citep{EG19b} is a symbolic time series representation method that applicable to general time series. It is based on an adaptive polygonal chain approximation, followed by a mean-based clustering algorithm.  ABBA follows two steps to symbolise time series, namely compression and digitization, to transform time series into its symbolic representation. The benefits of symbolic time series representation by ABBA include but are not limited to: (1) ABBA symbolic representation is better at preserving the original shape of time series through the empirical results in performance profiles \citep{EG19b}; (2) the symbolic sequence can reflect the local up and down behavior of the time series and help find the repeated motif in time series. (3) With respect to time series forecasting, symbolic representation transformed by ABBA has recently been demonstrated to reduce sensitivity to the LSTM hyper-parameters and the initialization of random weights against original time series \citep{EG20b}.  


![Speed comparison of Julia ABBA and Python ABBA.\label{fig:comsort_center}](BOXPLOT.png)



There is already ABBA software available in Python. The software fABBA \footnote{https://github.com/nla-group/fABBA} also demonstrates an accelerated ABBA with appealing speed and tolerance-oriented digitization without the prior knowledge of specifying the number of symbols. Now our application of interest focuses on the question that is it possible to accelerate ABBA by preserving k-means clustering? The package provides lightweight Julia implementation of the ABBA method, also use ParallelKMeans.jl to achieve speedup in the digitization. However, the current approach based on k-means with scikit-learn \citep{scikit-learn} does not achieve satisfying speed. We propose a lightweight Julia package of implementing speedup ABBA, called ABBAj. On top of leveraging the appealing speed of Julia compared with Python, ABBAj uses the digitization method based on the light Julia package ParallelKMeans.jl to accelerate the ABBA algorithm. The figure, generated by running Julia ABBA and official Python ABBA \footnote{https://github.com/nla-group/ABBA} in 100 random noises with a length of 10000, demonstrates the ABBAj excellent speed against ABBA in Python. 


# Statement of Need

ABBAj is a Julia module for time series transformation with ABBA. With ABBAj, you can employ ABBA in an efficient way to symbolize time series and applied the symbolic representation to the downstream time series task such as classification and forecasting. Compared to the ABBA module, ABBAj enjoys significantly faster speed while retaining the consistent reconstruction error of representation.  
